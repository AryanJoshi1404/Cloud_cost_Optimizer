#  AI-Powered Cloud Cost Optimizer (LLM-Driven)

An intelligent, menu-driven CLI tool that analyzes cloud project requirements, generates realistic synthetic billing data, and provides actionable **multi-cloud cost optimization recommendations** using Large Language Models (LLMs).

This project is developed as part of an academic assignment to demonstrate proficiency in **backend development, LLM integration, structured JSON generation, and cloud cost analysis**.

---

## üìå Features Overview

- ‚úî Plain-English project requirement analysis  
- ‚úî LLM-based structured project profile extraction  
- ‚úî Budget-aware synthetic cloud billing generation  
- ‚úî Cost analysis with budget variance detection  
- ‚úî Actionable cost optimization recommendations  
- ‚úî Menu-driven CLI (Windows-friendly)  
- ‚úî Strict JSON-only LLM outputs with validation  

---

## üèóÔ∏è Project Structure

cloud_cost_optimizer/
‚îÇ
‚îú‚îÄ‚îÄ src/
‚îÇ ‚îú‚îÄ‚îÄ main.py
‚îÇ ‚îú‚îÄ‚îÄ cli.py
‚îÇ ‚îú‚îÄ‚îÄ llm_client.py
‚îÇ ‚îú‚îÄ‚îÄ profile_extractor.py
‚îÇ ‚îú‚îÄ‚îÄ bill_generator.py
‚îÇ ‚îú‚îÄ‚îÄ cost_analyzer.py
‚îÇ ‚îú‚îÄ‚îÄ cost_optimizer.py
‚îÇ ‚îî‚îÄ‚îÄ report_builder.py
‚îÇ
‚îú‚îÄ‚îÄ data/
‚îÇ ‚îú‚îÄ‚îÄ project_description.txt
‚îÇ ‚îú‚îÄ‚îÄ project_profile.json
‚îÇ ‚îú‚îÄ‚îÄ mock_billing.json
‚îÇ ‚îî‚îÄ‚îÄ cost_optimization_report.json
‚îÇ
‚îú‚îÄ‚îÄ run.py
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ README.md
‚îî‚îÄ‚îÄ .gitignore

yaml
Copy code

> ‚ö†Ô∏è The `.env` file is intentionally excluded from version control for security reasons.

---

## üõ†Ô∏è Tech Stack

- **Language:** Python 3.10+  
- **LLM Provider:** Hugging Face Inference API  
- **Model Used:** `meta-llama/Meta-Llama-3-8B-Instruct`  
- **CLI Interface:** Python Console  
- **Validation:** Strict JSON validation  
- **Environment Management:** `python-dotenv`  

---

## ‚öôÔ∏è Setup Instructions

### 1Ô∏è‚É£ Install Dependencies

From the project root directory, run:

```bash
pip install -r requirements.txt
2Ô∏è‚É£ Configure Environment Variables
Create a .env file in the root directory:

env
Copy code
HF_API_KEY=your_huggingface_api_key
HF_MODEL=meta-llama/Meta-Llama-3-8B-Instruct
üîê Ensure .env is listed in .gitignore.

‚ñ∂Ô∏è How to Run the Application
‚úÖ Recommended (Simple & Demo-Friendly)
bash
Copy code
python run.py
üîÅ Alternative (Module-Based Execution)
bash
Copy code
python -m src.main
Both commands start the same CLI interface.

üß≠ CLI Menu Options
markdown
Copy code
1. Provide Project Description
2. Run Complete Cost Analysis
3. View Recommendations
4. Exit
üîÑ Application Workflow
Step 1: Project Description (User Input)
User enters a free-form project description via CLI

Saved to:

bash
Copy code
data/project_description.txt
Step 2: Project Profile Extraction (LLM)
LLM extracts structured information:

Project name

Monthly budget

Tech stack

Non-functional requirements

Output:

bash
Copy code
data/project_profile.json
Step 3: Synthetic Billing Generation (LLM)
Generates 12‚Äì20 realistic billing records

Covers:

Compute

Database

Storage

Networking

Monitoring

Budget-aware and cloud-agnostic

Output:

bash
Copy code
data/mock_billing.json
Step 4: Cost Analysis & Optimization
Calculates:

Total monthly cost

Budget variance

Service-wise cost breakdown

Generates multi-cloud cost optimization recommendations

Output:

bash
Copy code
data/cost_optimization_report.json
üìÑ Sample Artifacts Included
project_description.txt

project_profile.json

mock_billing.json

cost_optimization_report.json

These files demonstrate the expected input and output formats.

‚ö†Ô∏è Error Handling & Validation
Strict JSON-only enforcement for all LLM outputs

File existence and size checks before reading

Clear CLI error messages (no silent failures)

Defensive handling of malformed or partial responses

ü§ñ AI Usage Disclosure
This project uses Large Language Models via the Hugging Face Inference API
(specifically meta-llama/Meta-Llama-3-8B-Instruct) for:

Project profile extraction

Synthetic billing generation

Cost optimization recommendation generation

All AI-generated outputs are strictly validated as JSON.
The developer fully understands and owns all submitted code.

üìå Known Limitations
Uses synthetic (mock) billing data

Not connected to real cloud billing APIs

Free-tier LLM rate limits may introduce latency

üöÄ Future Enhancements
HTML report export

Azure and GCP-specific billing formats

Cost visualization dashboards

Real cloud billing ingestion
